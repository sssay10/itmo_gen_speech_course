{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install TTS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:24:19.276812Z","iopub.execute_input":"2025-06-10T10:24:19.277055Z","iopub.status.idle":"2025-06-10T10:26:30.002291Z","shell.execute_reply.started":"2025-06-10T10:24:19.277029Z","shell.execute_reply":"2025-06-10T10:26:30.001381Z"}},"outputs":[{"name":"stdout","text":"Collecting TTS\n  Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.0.12)\nRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.15.2)\nRequirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (2.6.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from TTS) (2.6.0+cu124)\nRequirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.13.1)\nRequirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.11.0)\nCollecting scikit-learn>=1.3.0 (from TTS)\n  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\nRequirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (7.5.0)\nRequirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.67.1)\nCollecting anyascii>=0.3.0 (from TTS)\n  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (6.0.2)\nRequirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (2025.3.2)\nRequirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.11.18)\nRequirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (25.0)\nRequirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.1.0)\nCollecting pysbd>=0.3.4 (from TTS)\n  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.7)\nCollecting pandas<2.0,>=1.4 (from TTS)\n  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.7.2)\nCollecting trainer>=0.0.32 (from TTS)\n  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\nCollecting coqpit>=0.0.16 (from TTS)\n  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from TTS) (0.42.1)\nCollecting pypinyin (from TTS)\n  Downloading pypinyin-0.54.0-py2.py3-none-any.whl.metadata (12 kB)\nCollecting hangul-romanize (from TTS)\n  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\nCollecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS)\n  Downloading gruut-2.2.3.tar.gz (73 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting jamo (from TTS)\n  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from TTS) (3.9.1)\nCollecting g2pkk>=0.1.1 (from TTS)\n  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\nCollecting bangla (from TTS)\n  Downloading bangla-0.0.5-py3-none-any.whl.metadata (4.7 kB)\nCollecting bnnumerizer (from TTS)\n  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting bnunicodenormalizer (from TTS)\n  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.8.1)\nRequirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.51.3)\nCollecting encodec>=0.1.1 (from TTS)\n  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting unidecode>=1.3.2 (from TTS)\n  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\nCollecting num2words (from TTS)\n  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (3.8.5)\nRequirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.26.4)\nRequirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.60.0)\nRequirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.17.0)\nCollecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\nCollecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\nCollecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nCollecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.20.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.6)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (8.1.8)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (1.9.0)\nRequirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (10.6.0)\nRequirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (4.4.2)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.5.0)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.5.0.post1)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.13.2)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.1.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (2.9.0.post0)\nCollecting docopt>=0.6.2 (from num2words->TTS)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->TTS) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0,>=1.4->TTS) (2025.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->TTS) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->TTS) (1.17.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.9)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.3.4)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.15.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.11.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (75.2.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.5.0)\nCollecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n  Downloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting sudachidict_core>=20211220 (from spacy[ja]>=3->TTS)\n  Downloading sudachidict_core-20250515-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.18.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1->TTS)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1->TTS)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1->TTS)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1->TTS)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1->TTS)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1->TTS)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1->TTS)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->TTS) (1.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (7.0.0)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (2.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.31.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.5.3)\nRequirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.1->TTS) (0.5.13)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.22)\nRequirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.3.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.33.0->TTS) (1.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS) (3.0.2)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.17.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.3.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (4.3.8)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2025.4.26)\nRequirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS) (0.1.5)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.21.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (7.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.3->TTS) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.3->TTS) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.3->TTS) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.3->TTS) (2024.2.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.72.0rc1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.7)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.3->TTS) (2024.2.0)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.17.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\nDownloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl (937 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\nDownloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\nDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bangla-0.0.5-py3-none-any.whl (5.1 kB)\nDownloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\nDownloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\nDownloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\nDownloading pypinyin-0.54.0-py2.py3-none-any.whl (837 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.0/837.0 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\nDownloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sudachidict_core-20250515-py3-none-any.whl (72.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: gruut, encodec, bnnumerizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75785 sha256=a4d7963209828c80e77066be5ed2050c2b424a2e16a4a4f168cc13c57482912c\n  Stored in directory: /root/.cache/pip/wheels/1f/a0/bc/4dacab52579ab464cffafbe7a8e3792dd36ad9ac288b264843\n  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=d970c81045272548fb2b21e2371b34a1c0083607b39ef3e2dfb410315d999623\n  Stored in directory: /root/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\n  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5260 sha256=ab947429c9f2d52a746c84f809c33b27f64188b43c0490cdaeab18e3353c1424\n  Stored in directory: /root/.cache/pip/wheels/9e/b9/e3/4145416693824818c0b931988a692676ecd4bbf2ea41d1eedd\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=1ad6639a0edb589a796ebbff3ef8f76a4bece347eb5c1f5fc6852811643c10d7\n  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=516bf795b388cf226e64d494d9f66c50c6f7230ad680d5106476e2317557c9da\n  Stored in directory: /root/.cache/pip/wheels/c7/10/89/a5908dd7a9a032229684b7679396785e19f816667f788087fb\n  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498314 sha256=e43a8f1463a7878c408678bdf07c6d4df623b17a91204048d866c012d2c2091e\n  Stored in directory: /root/.cache/pip/wheels/87/fa/df/5fdf5d3cc26ba859b8698a1f28581d1a6aa081edc6df9847ab\n  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326858 sha256=e6e7ecd810c58bd84d925a9770de9e818baff886f0246a85d93e51f7e08a0a66\n  Stored in directory: /root/.cache/pip/wheels/06/30/52/dc5cd222b4bbde285838fed1f96636e96f85cd75493e79a978\n  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173927 sha256=a3d75fe982a2647d89e11a5296bb3ed28b9c5040b483620b362ab3f146daa6d4\n  Stored in directory: /root/.cache/pip/wheels/c8/eb/59/30b5d15e56347e595f613036cbea0f807ad9621c75cd75d912\n  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=34a995d6dae210ee7e512f929a494057547e5fe70f3cda07de4ef1c3c51898fe\n  Stored in directory: /root/.cache/pip/wheels/e0/e7/a0/7c416a3eeaa94ca71bf7bcbc6289cced2263d8ba35e82444bb\nSuccessfully built gruut encodec bnnumerizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\nInstalling collected packages: sudachipy, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict_core, python-crfsuite, pysbd, pypinyin, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, num2words, networkx, jsonlines, gruut-ipa, coqpit, anyascii, nvidia-cusparse-cu12, nvidia-cudnn-cu12, g2pkk, dateparser, nvidia-cusolver-cu12, scikit-learn, gruut, trainer, pandas, encodec, TTS\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: networkx\n    Found existing installation: networkx 3.4.2\n    Uninstalling networkx-3.4.2:\n      Successfully uninstalled networkx-3.4.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.3\n    Uninstalling pandas-2.2.3:\n      Successfully uninstalled pandas-2.2.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\ncudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nvisions 0.8.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\nmizani 0.13.2 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\nscikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\nnx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nplotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\nxarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 bangla-0.0.5 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 networkx-2.8.8 num2words-0.5.14 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pandas-1.5.3 pypinyin-0.54.0 pysbd-0.3.4 python-crfsuite-0.9.11 scikit-learn-1.7.0 sudachidict_core-20250515 sudachipy-0.6.10 trainer-0.0.36 unidecode-1.4.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!wget \"https://www.dropbox.com/scl/fi/1snfy7wz4zh6yk4blnxqk/gen_speech_checkpoints.zip?rlkey=x2dvhmdcjzlmr8hqe41j2zhwy&st=r2hqv0s3&dl=0\" -O gen_speech_checkpoints.zip ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:26:30.003387Z","iopub.execute_input":"2025-06-10T10:26:30.003679Z","iopub.status.idle":"2025-06-10T10:26:41.550786Z","shell.execute_reply.started":"2025-06-10T10:26:30.003648Z","shell.execute_reply":"2025-06-10T10:26:41.550117Z"}},"outputs":[{"name":"stdout","text":"--2025-06-10 10:26:30--  https://www.dropbox.com/scl/fi/1snfy7wz4zh6yk4blnxqk/gen_speech_checkpoints.zip?rlkey=x2dvhmdcjzlmr8hqe41j2zhwy&st=r2hqv0s3&dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.85.18, 2620:100:6035:18::a27d:5512\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.85.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://ucf56e2e8cd10fae36bedb32a33a.dl.dropboxusercontent.com/cd/0/inline/CrUK_7rRsjtlR-8uIPEteZlzXyCYJZVscN1iu6dLvM1vKcNsQunUN99FN0UJqzzPx2kyBjwngXGVPtu7P4lxoCJzVJpN-kfQROl1aIUYiZyq464DU09vt8d7EjJ87VKcH80lvOmBbLhMpcfZUsOgH-Nn/file# [following]\n--2025-06-10 10:26:30--  https://ucf56e2e8cd10fae36bedb32a33a.dl.dropboxusercontent.com/cd/0/inline/CrUK_7rRsjtlR-8uIPEteZlzXyCYJZVscN1iu6dLvM1vKcNsQunUN99FN0UJqzzPx2kyBjwngXGVPtu7P4lxoCJzVJpN-kfQROl1aIUYiZyq464DU09vt8d7EjJ87VKcH80lvOmBbLhMpcfZUsOgH-Nn/file\nResolving ucf56e2e8cd10fae36bedb32a33a.dl.dropboxusercontent.com (ucf56e2e8cd10fae36bedb32a33a.dl.dropboxusercontent.com)... 162.125.85.15, 2620:100:6035:15::a27d:550f\nConnecting to ucf56e2e8cd10fae36bedb32a33a.dl.dropboxusercontent.com (ucf56e2e8cd10fae36bedb32a33a.dl.dropboxusercontent.com)|162.125.85.15|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /cd/0/inline2/CrXvb8cRDD9SsaCVk3SkGFhnvMTrmT0GSSpQgHirQbjE13KkNMYaFrxSm3iQSSgdmdvtAYVx_H_39nCWn808LLfSzqezKnn35KCguNd-_2ilrXHP7FwMw-jPvEI1eBMX1razpJxlR6v54fyUmDLd5ShYYDhO2o8zC7TQ2p7T_PZVtuop_cL1byxYKQ9HwSbdrwqB94LRaDZqbCWFk8yggpv1uMakHzQvcTPZ1vpkGp9ZTOovREabUXe6SljBvDtnNWkFLgbpWCr3zVr5yB49z0lOkmKJPnX1MmL19Yx6TqZBHMBgwHRDxXrVn4An-m9V626Jbu5Nwl-PkXSVoRs_AkP5b8ptc3yvMhiwYbNX5hWkZTgFPOISrzcp50CYYDDLV6Y/file [following]\n--2025-06-10 10:26:31--  https://ucf56e2e8cd10fae36bedb32a33a.dl.dropboxusercontent.com/cd/0/inline2/CrXvb8cRDD9SsaCVk3SkGFhnvMTrmT0GSSpQgHirQbjE13KkNMYaFrxSm3iQSSgdmdvtAYVx_H_39nCWn808LLfSzqezKnn35KCguNd-_2ilrXHP7FwMw-jPvEI1eBMX1razpJxlR6v54fyUmDLd5ShYYDhO2o8zC7TQ2p7T_PZVtuop_cL1byxYKQ9HwSbdrwqB94LRaDZqbCWFk8yggpv1uMakHzQvcTPZ1vpkGp9ZTOovREabUXe6SljBvDtnNWkFLgbpWCr3zVr5yB49z0lOkmKJPnX1MmL19Yx6TqZBHMBgwHRDxXrVn4An-m9V626Jbu5Nwl-PkXSVoRs_AkP5b8ptc3yvMhiwYbNX5hWkZTgFPOISrzcp50CYYDDLV6Y/file\nReusing existing connection to ucf56e2e8cd10fae36bedb32a33a.dl.dropboxusercontent.com:443.\nHTTP request sent, awaiting response... 200 OK\nLength: 210657995 (201M) [application/zip]\nSaving to: ‘gen_speech_checkpoints.zip’\n\ngen_speech_checkpoi 100%[===================>] 200.90M  22.0MB/s    in 9.2s    \n\n2025-06-10 10:26:41 (21.9 MB/s) - ‘gen_speech_checkpoints.zip’ saved [210657995/210657995]\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:26:41.552583Z","iopub.execute_input":"2025-06-10T10:26:41.552784Z","iopub.status.idle":"2025-06-10T10:26:41.672294Z","shell.execute_reply.started":"2025-06-10T10:26:41.552763Z","shell.execute_reply":"2025-06-10T10:26:41.671671Z"}},"outputs":[{"name":"stdout","text":"gen_speech_checkpoints.zip  \u001b[0m\u001b[01;34mlightning_logs\u001b[0m/  test_sentences.zip\n\u001b[01;34mgen_speech_checpoints\u001b[0m/      \u001b[01;34mtest_sentences\u001b[0m/\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!unzip gen_speech_checkpoints.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:26:41.673517Z","iopub.execute_input":"2025-06-10T10:26:41.673784Z","iopub.status.idle":"2025-06-10T10:28:52.230399Z","shell.execute_reply.started":"2025-06-10T10:26:41.673760Z","shell.execute_reply":"2025-06-10T10:28:52.229506Z"}},"outputs":[{"name":"stdout","text":"Archive:  gen_speech_checkpoints.zip\nreplace gen_speech_checpoints/last.ckpt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"ls ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:29:24.512532Z","iopub.execute_input":"2025-06-10T10:29:24.512831Z","iopub.status.idle":"2025-06-10T10:29:24.653808Z","shell.execute_reply.started":"2025-06-10T10:29:24.512800Z","shell.execute_reply":"2025-06-10T10:29:24.653102Z"}},"outputs":[{"name":"stdout","text":"gen_speech_checkpoints.zip  \u001b[0m\u001b[01;34mlightning_logs\u001b[0m/  test_sentences.zip\n\u001b[01;34mgen_speech_checpoints\u001b[0m/      \u001b[01;34mtest_sentences\u001b[0m/\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# TextToSpecConverter","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchaudio\nfrom TTS.api import TTS\nfrom TTS.tts.utils.synthesis import synthesis\n\n\nclass TextToSpecConverter:\n    def __init__(self, model_name: str = \"tts_models/en/ljspeech/fast_pitch\", device: str = \"cpu\"):\n        self.model_name = model_name\n        self.device = device\n        self.tts_handler = TTS(model_name=model_name)\n        self.model = self.tts_handler.synthesizer.tts_model.to(device)\n        self.config = self.tts_handler.synthesizer.tts_config\n        self.use_cuda = device == \"cuda\"\n        print(f\"Model {model_name} loaded on {device}\")\n    \n    def text2spec(self, text: str):\n        \"\"\"\n        Convert text to mel spectrogram using pretrained TTS model.\n        Args:\n            text (str): Input text to convert to mel spectrogram\n        Returns:\n            mel_spec (numpy.ndarray): Mel spectrogram of the input text\n                with shape [C, T] = [num_mel_channels, num_frames]\n        \"\"\"\n        outputs = synthesis(\n            self.model,\n            text,\n            self.config,\n            self.use_cuda,\n            use_griffin_lim=False,\n            do_trim_silence=False\n        )\n        mel_spec = outputs[\"outputs\"][\"model_outputs\"][0].detach().cpu().numpy()\n        # denormalize tts output based on the tts audio config\n        mel_spec = self.model.ap.denormalize(mel_spec.T).T\n        return mel_spec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:29:27.208010Z","iopub.execute_input":"2025-06-10T10:29:27.208802Z","iopub.status.idle":"2025-06-10T10:29:27.215238Z","shell.execute_reply.started":"2025-06-10T10:29:27.208767Z","shell.execute_reply":"2025-06-10T10:29:27.214496Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/processed_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T18:35:51.830634Z","iopub.execute_input":"2025-06-09T18:35:51.831084Z","iopub.status.idle":"2025-06-09T18:35:51.977065Z","shell.execute_reply.started":"2025-06-09T18:35:51.831066Z","shell.execute_reply":"2025-06-09T18:35:51.976021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torchaudio\nfrom tqdm import tqdm\nfrom torchaudio.datasets import LJSPEECH\n\n\ndef preprocess_ljspeech(dataset, out_dir, device=\"cpu\"):\n    \"\"\"\n    Preprocess LJSpeech dataset and save preprocessed files.\n    \n    Args:\n        dataset: LJSpeech dataset instance\n        out_dir (str): Path to save preprocessed files\n        device (str): Device to use for processing ('cpu' or 'cuda')\n    \"\"\"\n    # Initialize text to spec converter\n    t2s = TextToSpecConverter(device=device)\n    \n    # Create output directory\n    os.makedirs(out_dir, exist_ok=True)\n    \n    # Process each file\n    for i in tqdm(range(len(dataset)), desc=\"Preprocessing LJSpeech\"):\n        # Load audio and text\n        waveform, sample_rate, text, normalized_text = dataset[i]\n        \n        # Convert to mono if stereo\n        if waveform.shape[0] > 1:\n            waveform = waveform[0:1]\n        waveform = waveform.squeeze(0)\n        \n        # Generate mel spectrogram from text\n        mel = t2s.text2spec(text)\n        mel = torch.tensor(mel, dtype=torch.float32)  # Shape: [T, C]\n        \n        # Create sample dictionary\n        sample = {\n            \"mel\": mel,  # [T, C]\n            \"audio\": waveform,  # [T]\n            \"text\": text,\n        }\n        \n        # Save preprocessed file\n        save_path = os.path.join(out_dir, f\"sample_{i:06d}.pt\")\n        torch.save(sample, save_path)\n\n    del t2s\n    torch.cuda.empty_cache()\n\n\nbase_dir = \"/kaggle/\"\nprocessed_dir = os.path.join(base_dir, \"processed_data\")\n\n# Set device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\n# Download and load dataset\nprint(\"Downloading LJSpeech dataset...\")\ndataset = LJSPEECH(root=base_dir, download=True)\nprint(f\"Dataset downloaded successfully! Number of samples: {len(dataset)}\")\n\n# Run preprocessing\npreprocess_ljspeech(dataset, processed_dir, device)\nprint(\"Preprocessing completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T18:35:51.978184Z","iopub.execute_input":"2025-06-09T18:35:51.978581Z","iopub.status.idle":"2025-06-09T18:51:45.194757Z","shell.execute_reply.started":"2025-06-09T18:35:51.978503Z","shell.execute_reply":"2025-06-09T18:51:45.194004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ls /kaggle/processed_data | tail -10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T18:51:45.195610Z","iopub.execute_input":"2025-06-09T18:51:45.196382Z","iopub.status.idle":"2025-06-09T18:51:45.515130Z","shell.execute_reply.started":"2025-06-09T18:51:45.196362Z","shell.execute_reply":"2025-06-09T18:51:45.514263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Module","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\n\n\nclass LJSpeechDataset(Dataset):\n    def __init__(self, preprocessed_dir):\n        self.preprocessed_dir = preprocessed_dir\n        self.files = sorted(\n            [f for f in os.listdir(preprocessed_dir) if f.endswith(\".pt\")]\n        )\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        data = torch.load(os.path.join(self.preprocessed_dir, self.files[idx]))\n        \n        # Normalize audio\n        audio = data[\"audio\"].float()\n        audio = audio / audio.abs().max()\n\n        return {\n            \"mel\": data[\"mel\"],\n            \"audio\": audio,\n            \"text\": data[\"text\"],\n            \"audio_length\": audio.shape[0]\n        }\n\n\nclass LJSpeechDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        data_dir: str = \"/kaggle/processed_data\",\n        batch_size: int = 16,\n        num_workers: int = 4,\n        pin_memory: bool = True\n    ):\n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.pin_memory = pin_memory\n\n    def setup(self, stage=None):\n\n        self.train_dataset = LJSpeechDataset(self.data_dir)\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            collate_fn=self.collate_fn\n        )\n\n    def val_dataloader(self):\n        # Add validation dataloader if needed\n        pass\n\n    @staticmethod\n    def collate_fn(batch):\n        # Extract data from batch\n        mels = [item[\"mel\"] for item in batch]\n        audios = [item[\"audio\"] for item in batch]\n        texts = [item[\"text\"] for item in batch]\n        audio_lengths = [item[\"audio_length\"] for item in batch]\n\n        # Get max lengths\n        max_mel_len = max(m.shape[0] for m in mels)\n        num_mels = mels[0].shape[1]\n        max_audio_len = max(audio_lengths)\n\n        # Create padded tensors\n        padded_mels = torch.zeros(len(mels), num_mels, max_mel_len)\n        padded_audios = torch.zeros(len(audios), max_audio_len)\n\n        # Fill padded tensors\n        for i, (mel, audio) in enumerate(zip(mels, audios)):\n            padded_mels[i, :, :mel.shape[0]] = mel.T\n            padded_audios[i, :audio.shape[0]] = audio\n\n        return {\n            \"mel\": padded_mels,\n            \"audio\": padded_audios,\n            \"text\": texts,\n            \"audio_length\": audio_lengths\n        }\n\n\ndata_module = LJSpeechDataModule(\n    data_dir=\"/kaggle/processed_data\",\n    batch_size=16,\n    num_workers=4\n)\n\n# Setup data\ndata_module.setup()\n\n# Get a batch\nbatch = next(iter(data_module.train_dataloader()))\nprint(\"Batch shapes:\")\nprint(f\"Mel spectrograms: {batch['mel'].shape}\")\nprint(f\"Audio: {batch['audio'].shape}\")\nprint(f\"Number of texts: {len(batch['text'])}\")\nprint(f\"Audio lengths: {len(batch['audio_length'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T18:51:45.516258Z","iopub.execute_input":"2025-06-09T18:51:45.516472Z","iopub.status.idle":"2025-06-09T18:51:55.771528Z","shell.execute_reply.started":"2025-06-09T18:51:45.516450Z","shell.execute_reply":"2025-06-09T18:51:55.770762Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchaudio\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport pytorch_lightning as pl\nfrom torch.nn.utils import weight_norm\nimport numpy as np\nfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\n\ndef WNConv1d(*args, **kwargs):\n    return weight_norm(nn.Conv1d(*args, **kwargs))\n\n\ndef WNConvTranspose1d(*args, **kwargs):\n    return weight_norm(nn.ConvTranspose1d(*args, **kwargs))\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, dilation=1):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.LeakyReLU(0.2),\n            nn.ReflectionPad1d(dilation),\n            WNConv1d(dim, dim, kernel_size=3, dilation=dilation),\n            nn.LeakyReLU(0.2),\n            WNConv1d(dim, dim, kernel_size=1),\n        )\n        self.shortcut = WNConv1d(dim, dim, kernel_size=1)\n\n    def forward(self, x):\n        return self.shortcut(x) + self.block(x)\n\n\nclass Generator(nn.Module):\n    def __init__(self, input_size, ngf, n_residual_layers):\n        super().__init__()\n        ratios = [8, 8, 2, 2]\n        self.hop_length = np.prod(ratios)\n        mult = int(2 ** len(ratios))\n\n        model = [\n            nn.ReflectionPad1d(3),\n            WNConv1d(input_size, mult * ngf, kernel_size=7, padding=0),\n        ]\n\n        for i, r in enumerate(ratios):\n            model += [\n                nn.LeakyReLU(0.2),\n                WNConvTranspose1d(\n                    mult * ngf,\n                    mult * ngf // 2,\n                    kernel_size=r * 2,\n                    stride=r,\n                    padding=r // 2 + r % 2,\n                    output_padding=r % 2,\n                ),\n            ]\n\n            for j in range(n_residual_layers):\n                model += [ResnetBlock(mult * ngf // 2, dilation=3 ** j)]\n\n            mult //= 2\n\n        model += [\n            nn.LeakyReLU(0.2),\n            nn.ReflectionPad1d(3),\n            WNConv1d(ngf, 1, kernel_size=7, padding=0),\n            nn.Tanh(),\n        ]\n\n        self.model = nn.Sequential(*model)\n        self.apply(weights_init)\n\n    def forward(self, x):\n        return self.model(x)\n\n\nclass NLayerDiscriminator(nn.Module):\n    def __init__(self, ndf, n_layers, downsampling_factor):\n        super().__init__()\n        model = nn.ModuleDict()\n\n        model[\"layer_0\"] = nn.Sequential(\n            nn.ReflectionPad1d(7),\n            WNConv1d(1, ndf, kernel_size=15),\n            nn.LeakyReLU(0.2, True),\n        )\n\n        nf = ndf\n        stride = downsampling_factor\n        for n in range(1, n_layers + 1):\n            nf_prev = nf\n            nf = min(nf * stride, 1024)\n\n            model[\"layer_%d\" % n] = nn.Sequential(\n                WNConv1d(\n                    nf_prev,\n                    nf,\n                    kernel_size=stride * 10 + 1,\n                    stride=stride,\n                    padding=stride * 5,\n                    groups=nf_prev // 4,\n                ),\n                nn.LeakyReLU(0.2, True),\n            )\n\n        nf = min(nf * 2, 1024)\n        model[\"layer_%d\" % (n_layers + 1)] = nn.Sequential(\n            WNConv1d(nf_prev, nf, kernel_size=5, stride=1, padding=2),\n            nn.LeakyReLU(0.2, True),\n        )\n\n        model[\"layer_%d\" % (n_layers + 2)] = WNConv1d(\n            nf, 1, kernel_size=3, stride=1, padding=1\n        )\n\n        self.model = model\n\n    def forward(self, x):\n        results = []\n        for key, layer in self.model.items():\n            x = layer(x)\n            results.append(x)\n        return results\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, num_D, ndf, n_layers, downsampling_factor):\n        super().__init__()\n        self.model = nn.ModuleDict()\n        for i in range(num_D):\n            self.model[f\"disc_{i}\"] = NLayerDiscriminator(\n                ndf, n_layers, downsampling_factor\n            )\n\n        self.downsample = nn.AvgPool1d(4, stride=2, padding=1, count_include_pad=False)\n        self.apply(weights_init)\n\n    def forward(self, x):\n        results = []\n        for key, disc in self.model.items():\n            results.append(disc(x))\n            x = self.downsample(x)\n        return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:29:39.349556Z","iopub.execute_input":"2025-06-10T10:29:39.350161Z","iopub.status.idle":"2025-06-10T10:29:39.366417Z","shell.execute_reply.started":"2025-06-10T10:29:39.350138Z","shell.execute_reply":"2025-06-10T10:29:39.365601Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class MelGAN(pl.LightningModule):\n    def __init__(\n        self,\n        input_size=80,\n        ngf=32,\n        ndf=16,\n        n_residual_layers=2,\n        n_disc_layers=4,\n        num_D=1,\n        downsampling_factor=4,\n        lr_g=2e-4,\n        lr_d=2e-4,\n        betas=(0.5, 0.9),\n        lambda_feat=10.0,  # Weight for feature matching loss\n        lr_scheduler_patience=5,\n        lr_scheduler_factor=0.5,\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        \n        # Initialize models\n        self.generator = Generator(input_size, ngf, n_residual_layers)\n        self.discriminator = Discriminator(num_D, ndf, n_disc_layers, downsampling_factor)\n        \n        # Initialize optimizers\n        self.lr_g = lr_g\n        self.lr_d = lr_d\n        self.betas = betas\n        self.lambda_feat = lambda_feat\n        \n        # For logging\n        self.automatic_optimization = False\n\n    def forward(self, x):\n        return self.generator(x)\n\n    def adversarial_loss(self, real_outputs, fake_outputs):\n        loss = 0\n        for real, fake in zip(real_outputs, fake_outputs):\n            # Get the minimum length to avoid shape mismatch\n            min_len = min(real[-1].size(-1), fake[-1].size(-1))\n            \n            # Truncate both outputs to the minimum length\n            real_output = real[-1][..., :min_len]\n            fake_output = fake[-1][..., :min_len]\n            \n            loss += F.relu(1 + fake_output).mean()\n            loss += F.relu(1 - real_output).mean()\n        return loss\n\n    def generator_loss(self, fake_outputs):\n        loss = 0\n        for fake in fake_outputs:\n            loss += -fake[-1].mean()\n        return loss\n\n    def feature_matching_loss(self, real_outputs, fake_outputs):\n        loss = 0\n        feat_weights = 4.0 / (self.hparams.n_disc_layers + 1)\n        D_weights = 1.0 / self.hparams.num_D\n        wt = D_weights * feat_weights\n        \n        for i in range(self.hparams.num_D):\n            for j in range(len(fake_outputs[i]) - 1):\n                # Get the current feature maps\n                real_feat = real_outputs[i][j]\n                fake_feat = fake_outputs[i][j]\n                \n                # Get the minimum length to avoid shape mismatch\n                min_len = min(real_feat.size(-1), fake_feat.size(-1))\n                \n                # Truncate both feature maps to the minimum length\n                real_feat = real_feat[..., :min_len]\n                fake_feat = fake_feat[..., :min_len]\n                \n                # Calculate L1 loss\n                feat_loss = F.l1_loss(fake_feat, real_feat.detach())\n                loss += wt * feat_loss\n        \n        return loss\n\n    def training_step(self, batch, batch_idx):\n        # Get optimizers\n        opt_g, opt_d = self.optimizers()\n        \n        # Get data from dictionary\n        mel = batch[\"mel\"]\n        real_audio = batch[\"audio\"].unsqueeze(1)  # Add channel dimension\n        \n        # Train discriminator\n        # Generate fake audio\n        fake_audio = self.generator(mel)\n        \n        # Get discriminator outputs\n        real_outputs = self.discriminator(real_audio)\n        fake_outputs = self.discriminator(fake_audio.detach())\n        \n        # Calculate discriminator loss\n        d_loss = self.adversarial_loss(real_outputs, fake_outputs)\n        \n        # Update discriminator\n        opt_d.zero_grad()\n        d_loss.backward()\n        opt_d.step()\n        \n        # Train generator\n        # Get discriminator outputs for generator\n        fake_outputs = self.discriminator(fake_audio)\n        \n        # Calculate generator losses\n        g_loss = self.generator_loss(fake_outputs)\n        feat_loss = self.feature_matching_loss(real_outputs, fake_outputs)\n        \n        # Total generator loss\n        total_g_loss = g_loss + self.lambda_feat * feat_loss\n        \n        # Update generator\n        opt_g.zero_grad()\n        total_g_loss.backward()\n        opt_g.step()\n        \n        # Log losses\n        self.log_dict({\n            \"g_loss\": g_loss,\n            \"d_loss\": d_loss,\n            \"feat_loss\": feat_loss,\n            \"total_g_loss\": total_g_loss,\n        }, prog_bar=True)\n        \n        return {\n            \"g_loss\": g_loss,\n            \"d_loss\": d_loss,\n            \"feat_loss\": feat_loss,\n            \"total_g_loss\": total_g_loss\n        }\n\n    def configure_optimizers(self):\n        opt_g = optim.Adam(\n            self.generator.parameters(),\n            lr=self.lr_g,\n            betas=self.betas\n        )\n        opt_d = optim.Adam(\n            self.discriminator.parameters(),\n            lr=self.lr_d,\n            betas=self.betas\n        )\n        \n        # Learning rate schedulers\n        scheduler_g = {\n            \"scheduler\": ReduceLROnPlateau(\n                opt_g,\n                mode='min',\n                factor=self.hparams.lr_scheduler_factor,\n                patience=self.hparams.lr_scheduler_patience,\n                verbose=True\n            ),\n            \"monitor\": \"total_g_loss\"\n        }\n        \n        scheduler_d = {\n            \"scheduler\": ReduceLROnPlateau(\n                opt_d,\n                mode='min',\n                factor=self.hparams.lr_scheduler_factor,\n                patience=self.hparams.lr_scheduler_patience,\n                verbose=True\n            ),\n            \"monitor\": \"total_g_loss\"\n        }\n        \n        return [opt_g, opt_d], [scheduler_g, scheduler_d]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:29:45.689927Z","iopub.execute_input":"2025-06-10T10:29:45.690539Z","iopub.status.idle":"2025-06-10T10:29:45.704023Z","shell.execute_reply.started":"2025-06-10T10:29:45.690516Z","shell.execute_reply":"2025-06-10T10:29:45.703267Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"data_module = LJSpeechDataModule(\n    data_dir=\"/kaggle/processed_data\",\n    batch_size=4,\n    num_workers=4\n)\ndata_module.setup()\n\n# Create model\nmodel = MelGAN(\n    lambda_feat=8.0,  # Set feature matching loss weight\n    lr_scheduler_patience=5,\n    lr_scheduler_factor=0.5\n)\n# checkpoint_path = \"/kaggle/working/melgan-epoch=02-total_g_loss=12.29.ckpt\"\n# model = MelGAN.load_from_checkpoint(\n#     checkpoint_path,\n#     input_size=80,\n#     ngf=32,\n#     ndf=16,\n#     n_residual_layers=2,\n#     n_disc_layers=4,\n#     num_D=1,\n#     downsampling_factor=4,\n#     lambda_feat=5.0,\n# )\n\n# Create checkpoint callback\ncheckpoint_callback = ModelCheckpoint(\n    dirpath='/kaggle/working',\n    filename='melgan-{epoch:02d}-{total_g_loss:.2f}',\n    save_top_k=-1,\n    monitor='g_loss',\n    mode='min',\n    save_last=True,\n    save_on_train_epoch_end=True\n)\n\n# Create learning rate monitor\nlr_monitor = LearningRateMonitor(logging_interval='epoch')\n\n# Create trainer\ntrainer = pl.Trainer(\n    max_epochs=30,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    devices=1,\n    callbacks=[checkpoint_callback, lr_monitor],\n)\n\n# Train model\ntrainer.fit(model, train_dataloaders=data_module.train_dataloader())\n# trainer.fit(model, train_dataloaders=data_module.train_dataloader(), ckpt_path=checkpoint_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:22:24.815173Z","iopub.execute_input":"2025-06-09T19:22:24.815802Z","execution_failed":"2025-06-09T19:26:01.561Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test samples","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchaudio\nimport os\nfrom tqdm import tqdm\n\n\ndef load_model(checkpoint_path, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \"\"\"Load model from checkpoint\"\"\"\n    # Initialize model with the same hyperparameters as training\n    model = MelGAN(\n        input_size=80,  # mel spectrogram dimension\n        ngf=32,\n        ndf=16,\n        n_residual_layers=2,\n        n_disc_layers=4,\n        num_D=1,\n        downsampling_factor=4,\n        lambda_feat=10.0\n    )\n    \n    # Load checkpoint\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint['state_dict'])\n    model = model.to(device)\n    model.eval()\n    \n    return model\n\ndef text_to_wav(model, text, output_path, sample_rate=22050):\n    \"\"\"Convert text to waveform and save to file\"\"\"\n    # Convert text to mel spectrogram using your text-to-spec model\n    # This is a placeholder - you'll need to implement your text-to-spec conversion\n    t2s = TextToSpecConverter()  # Your text-to-spec model\n    mel_spec = t2s.text2spec(text)\n    \n    # Convert mel spectrogram to tensor and add batch dimension\n    mel_spec = torch.from_numpy(mel_spec).float().unsqueeze(0)\n    \n    # Move to device\n    device = next(model.parameters()).device\n    mel_spec = mel_spec.to(device)\n    \n    # Generate waveform\n    with torch.no_grad():\n        print(f\"mel_spec shape: {mel_spec.transpose(1, 2).shape}\")\n        waveform = model(mel_spec.transpose(1, 2))\n    \n    # Remove batch dimension and move to CPU\n    waveform = waveform.squeeze(0).cpu()\n    \n    # Save to file\n    torchaudio.save(\n        output_path,\n        waveform,\n        sample_rate\n    )\n    \n    return output_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:29:49.828291Z","iopub.execute_input":"2025-06-10T10:29:49.828607Z","iopub.status.idle":"2025-06-10T10:29:49.835580Z","shell.execute_reply.started":"2025-06-10T10:29:49.828584Z","shell.execute_reply":"2025-06-10T10:29:49.834805Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"ls gen_speech_checpoints","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:32:54.048379Z","iopub.execute_input":"2025-06-10T10:32:54.048967Z","iopub.status.idle":"2025-06-10T10:32:54.229484Z","shell.execute_reply.started":"2025-06-10T10:32:54.048936Z","shell.execute_reply":"2025-06-10T10:32:54.228758Z"}},"outputs":[{"name":"stdout","text":" last.ckpt  'melgan-epoch=22-total_g_loss=26.41.ckpt'\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"!rm -r test_sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:33:17.838673Z","iopub.execute_input":"2025-06-10T10:33:17.838988Z","iopub.status.idle":"2025-06-10T10:33:18.012183Z","shell.execute_reply.started":"2025-06-10T10:33:17.838958Z","shell.execute_reply":"2025-06-10T10:33:18.011401Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"!rm test_sentences.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:33:19.237490Z","iopub.execute_input":"2025-06-10T10:33:19.237777Z","iopub.status.idle":"2025-06-10T10:33:19.414727Z","shell.execute_reply.started":"2025-06-10T10:33:19.237750Z","shell.execute_reply":"2025-06-10T10:33:19.413803Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"!mkdir test_sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:33:20.647378Z","iopub.execute_input":"2025-06-10T10:33:20.647694Z","iopub.status.idle":"2025-06-10T10:33:20.822632Z","shell.execute_reply.started":"2025-06-10T10:33:20.647665Z","shell.execute_reply":"2025-06-10T10:33:20.821684Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"test_sentences = [\n    \"Tourists found the octagonal lighthouse after a two-mile hike through fog\",\n    \"In twenty forty-nine, neural implants became standard for city workers\",\n    \"He whispered something in Icelandic I could not quite translate\",\n    \"Lucia balanced a porcelain vase on her elbow without flinching\",\n    \"They gathered quietly beneath the turbine as the wind picked up speed\",\n]\n\n\ncheckpoint = \"/kaggle/working/gen_speech_checpoints/last.ckpt\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Loading model from {checkpoint}...\")\nmodel = load_model(checkpoint, device)\n\n# Generate audio\nfor idx, sentence in enumerate(test_sentences):\n    print(f\"Generating audio for text: {sentence}\")\n    output_path = text_to_wav(model, sentence, f\"/kaggle/working/test_sentences/test_sentences_{idx}.wav\")\n\n    print(f\"Audio saved to: {output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:52:46.510958Z","iopub.execute_input":"2025-06-10T10:52:46.511686Z","iopub.status.idle":"2025-06-10T10:52:56.482421Z","shell.execute_reply.started":"2025-06-10T10:52:46.511652Z","shell.execute_reply":"2025-06-10T10:52:56.481736Z"}},"outputs":[{"name":"stdout","text":"Loading model from /kaggle/working/gen_speech_checpoints/last.ckpt...\nGenerating audio for text: Tourists found the octagonal lighthouse after a two-mile hike through fog\n > tts_models/en/ljspeech/fast_pitch is already downloaded.\n > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n > Using model: fast_pitch\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:True\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Vocoder Model: hifigan\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:False\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Generator Model: hifigan_generator\n > Discriminator Model: hifigan_discriminator\nRemoving weight norm...\nModel tts_models/en/ljspeech/fast_pitch loaded on cpu\nmel_spec shape: torch.Size([1, 80, 415])\nAudio saved to: /kaggle/working/test_sentences/test_sentences_0.wav\nGenerating audio for text: In twenty forty-nine, neural implants became standard for city workers\n > tts_models/en/ljspeech/fast_pitch is already downloaded.\n > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n > Using model: fast_pitch\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:True\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Vocoder Model: hifigan\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:False\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Generator Model: hifigan_generator\n > Discriminator Model: hifigan_discriminator\nRemoving weight norm...\nModel tts_models/en/ljspeech/fast_pitch loaded on cpu\nmel_spec shape: torch.Size([1, 80, 417])\nAudio saved to: /kaggle/working/test_sentences/test_sentences_1.wav\nGenerating audio for text: He whispered something in Icelandic I could not quite translate\n > tts_models/en/ljspeech/fast_pitch is already downloaded.\n > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n > Using model: fast_pitch\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:True\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Vocoder Model: hifigan\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:False\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Generator Model: hifigan_generator\n > Discriminator Model: hifigan_discriminator\nRemoving weight norm...\nModel tts_models/en/ljspeech/fast_pitch loaded on cpu\nmel_spec shape: torch.Size([1, 80, 305])\nAudio saved to: /kaggle/working/test_sentences/test_sentences_2.wav\nGenerating audio for text: Lucia balanced a porcelain vase on her elbow without flinching\n > tts_models/en/ljspeech/fast_pitch is already downloaded.\n > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n > Using model: fast_pitch\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:True\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Vocoder Model: hifigan\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:False\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Generator Model: hifigan_generator\n > Discriminator Model: hifigan_discriminator\nRemoving weight norm...\nModel tts_models/en/ljspeech/fast_pitch loaded on cpu\nluʃə bælənst ə pɔɹsələn veɪz ɔn hɚ ɛlboʊ wɪðaʊt flɪnt͡ʃɪŋ\n [!] Character '͡' not found in the vocabulary. Discarding it.\nmel_spec shape: torch.Size([1, 80, 366])\nAudio saved to: /kaggle/working/test_sentences/test_sentences_3.wav\nGenerating audio for text: They gathered quietly beneath the turbine as the wind picked up speed\n > tts_models/en/ljspeech/fast_pitch is already downloaded.\n > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n > Using model: fast_pitch\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:True\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Vocoder Model: hifigan\n > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:80\n | > log_func:np.log\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:False\n | > symmetric_norm:True\n | > mel_fmin:0\n | > mel_fmax:8000.0\n | > pitch_fmin:1.0\n | > pitch_fmax:640.0\n | > spec_gain:1.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:False\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:2.718281828459045\n | > hop_length:256\n | > win_length:1024\n > Generator Model: hifigan_generator\n > Discriminator Model: hifigan_discriminator\nRemoving weight norm...\nModel tts_models/en/ljspeech/fast_pitch loaded on cpu\nmel_spec shape: torch.Size([1, 80, 325])\nAudio saved to: /kaggle/working/test_sentences/test_sentences_4.wav\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!rm -r test_sentences","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir test_sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T09:26:28.923952Z","iopub.execute_input":"2025-06-10T09:26:28.924287Z","iopub.status.idle":"2025-06-10T09:26:29.103333Z","shell.execute_reply.started":"2025-06-10T09:26:28.924239Z","shell.execute_reply":"2025-06-10T09:26:29.102204Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"!mv test_sentences_4.wav test_sentences/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T09:26:42.553801Z","iopub.execute_input":"2025-06-10T09:26:42.554609Z","iopub.status.idle":"2025-06-10T09:26:42.727007Z","shell.execute_reply.started":"2025-06-10T09:26:42.554580Z","shell.execute_reply":"2025-06-10T09:26:42.725932Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"ls test_sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:53:44.929624Z","iopub.execute_input":"2025-06-10T10:53:44.930213Z","iopub.status.idle":"2025-06-10T10:53:45.120587Z","shell.execute_reply.started":"2025-06-10T10:53:44.930182Z","shell.execute_reply":"2025-06-10T10:53:45.119819Z"}},"outputs":[{"name":"stdout","text":"test_sentences_0.wav  test_sentences_2.wav  test_sentences_4.wav\ntest_sentences_1.wav  test_sentences_3.wav\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"!zip -r test_sentences.zip test_sentences/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:54:46.489845Z","iopub.execute_input":"2025-06-10T10:54:46.490152Z","iopub.status.idle":"2025-06-10T10:54:46.725025Z","shell.execute_reply.started":"2025-06-10T10:54:46.490124Z","shell.execute_reply":"2025-06-10T10:54:46.724337Z"}},"outputs":[{"name":"stdout","text":"updating: test_sentences/ (stored 0%)\nupdating: test_sentences/test_sentences_0.wav (deflated 15%)\nupdating: test_sentences/test_sentences_1.wav (deflated 16%)\nupdating: test_sentences/test_sentences_4.wav (deflated 17%)\nupdating: test_sentences/test_sentences_3.wav (deflated 17%)\nupdating: test_sentences/test_sentences_2.wav (deflated 16%)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}